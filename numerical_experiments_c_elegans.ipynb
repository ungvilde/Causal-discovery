{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e2818ca-da31-4771-81fc-fa95b89ee854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import statsmodels.api as sm\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "\n",
    "from spikeometric.models import BernoulliGLM\n",
    "from spikeometric.datasets import NormalGenerator, ConnectivityDataset\n",
    "from spikeometric.stimulus import RegularStimulus\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_dense_adj, to_networkx, from_networkx\n",
    "from CD_methods import SCM_learner\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516d4dda-3f6d-4f4a-a971-e70e95ea6de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_data = torch.load('data/c_elegans_data.pt')\n",
    "\n",
    "with open('data/c_elegans_spike_data_single_node_stimuli.pickle', 'rb') as f:\n",
    "    spike_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54b1b9a0-4e81-4ed3-93f7-6daa9e6eb742",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_neurons = network_data.num_nodes\n",
    "\n",
    "G = to_networkx(network_data, node_attrs = ['position'])\n",
    "position_dict = nx.get_node_attributes(G, 'position')\n",
    "\n",
    "# sample neurons\n",
    "n_obs = 90\n",
    "index_obs = np.sort(np.random.choice(n_neurons, size = n_obs, replace = False))\n",
    "\n",
    "stimulation_protocol = [[i] for i in index_obs]\n",
    "spike_data_obs = dict()\n",
    "spike_data_obs['null'] = spike_data['null'][index_obs]\n",
    "for intervention in index_obs:\n",
    "    spike_data_obs[str(intervention)] = spike_data[str(intervention)][index_obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9ea5dc9-3e3f-4f14-8eeb-ddc11f31f318",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num. confounding variables =  101\n"
     ]
    }
   ],
   "source": [
    "G_obs = nx.subgraph(G, index_obs)\n",
    "index_hidden = [node for node in range(n_neurons) if node not in index_obs]\n",
    "confounders = []\n",
    "for node in index_hidden:\n",
    "    count = 0\n",
    "    for _, v in G.out_edges(node):\n",
    "        if v in index_obs:\n",
    "            count += 1\n",
    "    if count >= 2:\n",
    "        confounders.append(node)\n",
    "print('num. confounding variables = ',len(confounders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32eb2466-eb81-4167-9e14-768bd8ac24a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 74.39it/s]\n"
     ]
    }
   ],
   "source": [
    "G_learned = SCM_learner(spike_data_obs, \n",
    "                        node_list=index_obs, \n",
    "                        stimulation_protocol=stimulation_protocol, \n",
    "                        alpha = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b552b65-01eb-4ccb-8482-2da4e523de1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num. confounding variables =  101\n",
      "total edges (in true observed graph) =  190\n",
      "percentage of nodes observed =  32.26 %\n",
      "SHD =  0\n",
      "True positives =  190 , Sensitivity =  100.0\n",
      "True negatives =  7910 , Specificity =  100.0\n",
      "False positives =  0\n",
      "False negatives =  0\n"
     ]
    }
   ],
   "source": [
    "G_true = nx.subgraph(G, index_obs)\n",
    "\n",
    "A_true = nx.adjacency_matrix(G_true).todense() \n",
    "A_learned = nx.adjacency_matrix(G_learned).todense() \n",
    "A_diff = A_true - A_learned\n",
    "\n",
    "SHD = np.sum(np.abs(A_true- A_learned))\n",
    "TP = np.sum( (A_true == 1)*(A_learned==1) )\n",
    "TN = np.sum( (A_true == 0)*(A_learned==0)) \n",
    "FP = np.sum(A_diff == -1)\n",
    "FN = np.sum(A_diff == 1) \n",
    "\n",
    "index_hidden = [node for node in range(n_neurons) if node not in index_obs]\n",
    "confounders = []\n",
    "for node in index_hidden:\n",
    "    count = 0\n",
    "    for _, v in G.out_edges(node):\n",
    "        if v in index_obs:\n",
    "            count += 1\n",
    "    if count >= 2:\n",
    "        confounders.append(node)\n",
    "print('num. confounding variables = ', len(confounders))\n",
    "\n",
    "print('total edges (in true observed graph) = ',G_true.number_of_edges())\n",
    "print('percentage of nodes observed = ', np.round(G_obs.number_of_nodes() / G.number_of_nodes() * 100, 2), '%')\n",
    "print('SHD = ', SHD)\n",
    "print('True positives = ', TP, ', Sensitivity = ', np.round(TP / (TP + FP) * 100, 2) )\n",
    "print('True negatives = ', TN, ', Specificity = ', np.round(TN / (TN + FN)*100, 2) )\n",
    "print('False positives = ', FP )\n",
    "print('False negatives = ', FN )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33e9bbaa-c38e-4d6f-b022-7207a8f5a37f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_obs =  10\n",
      "num. confounding variables =  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 3222.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  3.58 %\n",
      "SHD =  2\n",
      "True positives =  0 , Sensitivity =  0.0\n",
      "True negatives =  98 , Specificity =  98.99\n",
      "False positives =  1\n",
      "False negatives =  1\n",
      "\n",
      "n_obs =  20\n",
      "num. confounding variables =  43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████| 20/20 [00:00<00:00, 346.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  7.17 %\n",
      "SHD =  28\n",
      "True positives =  0 , Sensitivity =  0.0\n",
      "True negatives =  372 , Specificity =  96.37\n",
      "False positives =  14\n",
      "False negatives =  14\n",
      "\n",
      "n_obs =  30\n",
      "num. confounding variables =  59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 30/30 [00:00<00:00, 727.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  10.75 %\n",
      "SHD =  34\n",
      "True positives =  0 , Sensitivity =  0.0\n",
      "True negatives =  866 , Specificity =  98.07\n",
      "False positives =  17\n",
      "False negatives =  17\n",
      "\n",
      "n_obs =  40\n",
      "num. confounding variables =  76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 239.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  14.34 %\n",
      "SHD =  82\n",
      "True positives =  3 , Sensitivity =  6.82\n",
      "True negatives =  1515 , Specificity =  97.37\n",
      "False positives =  41\n",
      "False negatives =  41\n",
      "\n",
      "n_obs =  50\n",
      "num. confounding variables =  75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 50/50 [00:00<00:00, 149.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  17.92 %\n",
      "SHD =  129\n",
      "True positives =  0 , Sensitivity =  0.0\n",
      "True negatives =  2371 , Specificity =  97.37\n",
      "False positives =  65\n",
      "False negatives =  64\n",
      "\n",
      "n_obs =  60\n",
      "num. confounding variables =  98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 60/60 [00:00<00:00, 119.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  21.51 %\n",
      "SHD =  174\n",
      "True positives =  5 , Sensitivity =  5.43\n",
      "True negatives =  3421 , Specificity =  97.52\n",
      "False positives =  87\n",
      "False negatives =  87\n",
      "\n",
      "n_obs =  70\n",
      "num. confounding variables =  89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 137.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  25.09 %\n",
      "SHD =  190\n",
      "True positives =  2 , Sensitivity =  2.06\n",
      "True negatives =  4708 , Specificity =  98.02\n",
      "False positives =  95\n",
      "False negatives =  95\n",
      "\n",
      "n_obs =  80\n",
      "num. confounding variables =  107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [00:01<00:00, 47.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  28.67 %\n",
      "SHD =  1\n",
      "True positives =  232 , Sensitivity =  99.57\n",
      "True negatives =  6167 , Specificity =  100.0\n",
      "False positives =  1\n",
      "False negatives =  0\n",
      "\n",
      "n_obs =  90\n",
      "num. confounding variables =  103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 90/90 [00:01<00:00, 50.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  32.26 %\n",
      "SHD =  0\n",
      "True positives =  254 , Sensitivity =  100.0\n",
      "True negatives =  7846 , Specificity =  100.0\n",
      "False positives =  0\n",
      "False negatives =  0\n",
      "\n",
      "n_obs =  100\n",
      "num. confounding variables =  109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:01<00:00, 51.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  35.84 %\n",
      "SHD =  1\n",
      "True positives =  268 , Sensitivity =  99.63\n",
      "True negatives =  9731 , Specificity =  100.0\n",
      "False positives =  1\n",
      "False negatives =  0\n",
      "\n",
      "n_obs =  110\n",
      "num. confounding variables =  111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 110/110 [00:02<00:00, 45.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  39.43 %\n",
      "SHD =  4\n",
      "True positives =  333 , Sensitivity =  99.11\n",
      "True negatives =  11763 , Specificity =  99.99\n",
      "False positives =  3\n",
      "False negatives =  1\n",
      "\n",
      "n_obs =  120\n",
      "num. confounding variables =  101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 120/120 [00:03<00:00, 36.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  43.01 %\n",
      "SHD =  1\n",
      "True positives =  410 , Sensitivity =  99.76\n",
      "True negatives =  13989 , Specificity =  100.0\n",
      "False positives =  1\n",
      "False negatives =  0\n",
      "\n",
      "n_obs =  130\n",
      "num. confounding variables =  102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 130/130 [00:04<00:00, 26.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  46.59 %\n",
      "SHD =  5\n",
      "True positives =  521 , Sensitivity =  99.43\n",
      "True negatives =  16374 , Specificity =  99.99\n",
      "False positives =  3\n",
      "False negatives =  2\n",
      "\n",
      "n_obs =  140\n",
      "num. confounding variables =  94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 140/140 [00:05<00:00, 23.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  50.18 %\n",
      "SHD =  2\n",
      "True positives =  635 , Sensitivity =  100.0\n",
      "True negatives =  18963 , Specificity =  99.99\n",
      "False positives =  0\n",
      "False negatives =  2\n",
      "\n",
      "n_obs =  150\n",
      "num. confounding variables =  94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 150/150 [00:06<00:00, 21.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  53.76 %\n",
      "SHD =  3\n",
      "True positives =  720 , Sensitivity =  99.59\n",
      "True negatives =  21777 , Specificity =  100.0\n",
      "False positives =  3\n",
      "False negatives =  0\n",
      "\n",
      "n_obs =  160\n",
      "num. confounding variables =  91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 160/160 [00:08<00:00, 18.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  57.35 %\n",
      "SHD =  2\n",
      "True positives =  855 , Sensitivity =  99.88\n",
      "True negatives =  24743 , Specificity =  100.0\n",
      "False positives =  1\n",
      "False negatives =  1\n",
      "\n",
      "n_obs =  170\n",
      "num. confounding variables =  83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 170/170 [00:07<00:00, 23.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  60.93 %\n",
      "SHD =  3\n",
      "True positives =  757 , Sensitivity =  99.61\n",
      "True negatives =  28140 , Specificity =  100.0\n",
      "False positives =  3\n",
      "False negatives =  0\n",
      "\n",
      "n_obs =  180\n",
      "num. confounding variables =  76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 180/180 [00:08<00:00, 20.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  64.52 %\n",
      "SHD =  5\n",
      "True positives =  886 , Sensitivity =  99.44\n",
      "True negatives =  31509 , Specificity =  100.0\n",
      "False positives =  5\n",
      "False negatives =  0\n",
      "\n",
      "n_obs =  190\n",
      "num. confounding variables =  74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 190/190 [00:10<00:00, 18.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  68.1 %\n",
      "SHD =  3\n",
      "True positives =  938 , Sensitivity =  99.68\n",
      "True negatives =  35159 , Specificity =  100.0\n",
      "False positives =  3\n",
      "False negatives =  0\n",
      "\n",
      "n_obs =  200\n",
      "num. confounding variables =  67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 200/200 [00:12<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  71.68 %\n",
      "SHD =  1\n",
      "True positives =  1061 , Sensitivity =  100.0\n",
      "True negatives =  38938 , Specificity =  100.0\n",
      "False positives =  0\n",
      "False negatives =  1\n",
      "\n",
      "n_obs =  210\n",
      "num. confounding variables =  54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 210/210 [00:20<00:00, 10.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  75.27 %\n",
      "SHD =  6\n",
      "True positives =  1281 , Sensitivity =  99.61\n",
      "True negatives =  42813 , Specificity =  100.0\n",
      "False positives =  5\n",
      "False negatives =  1\n",
      "\n",
      "n_obs =  220\n",
      "num. confounding variables =  48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 220/220 [00:22<00:00,  9.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  78.85 %\n",
      "SHD =  5\n",
      "True positives =  1415 , Sensitivity =  99.65\n",
      "True negatives =  46980 , Specificity =  100.0\n",
      "False positives =  5\n",
      "False negatives =  0\n",
      "\n",
      "n_obs =  230\n",
      "num. confounding variables =  37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 230/230 [00:24<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  82.44 %\n",
      "SHD =  6\n",
      "True positives =  1484 , Sensitivity =  99.66\n",
      "True negatives =  51410 , Specificity =  100.0\n",
      "False positives =  5\n",
      "False negatives =  1\n",
      "\n",
      "n_obs =  240\n",
      "num. confounding variables =  35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 240/240 [00:23<00:00, 10.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  86.02 %\n",
      "SHD =  11\n",
      "True positives =  1545 , Sensitivity =  99.36\n",
      "True negatives =  56044 , Specificity =  100.0\n",
      "False positives =  10\n",
      "False negatives =  1\n",
      "\n",
      "n_obs =  250\n",
      "num. confounding variables =  24\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m         confounders\u001b[38;5;241m.\u001b[39mappend(node)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum. confounding variables = \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mlen\u001b[39m(confounders))\n\u001b[0;32m---> 23\u001b[0m G_learned \u001b[38;5;241m=\u001b[39m \u001b[43mSCM_learner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspike_data_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mnode_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstimulation_protocol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstimulation_protocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m G_true \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39msubgraph(G, index_obs)\n\u001b[1;32m     30\u001b[0m A_true \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39madjacency_matrix(G_true)\u001b[38;5;241m.\u001b[39mtodense() \n",
      "File \u001b[0;32m~/Documents/Masteroppgave/code/causal_discovery/causal_discovery/CD_methods.py:47\u001b[0m, in \u001b[0;36mSCM_learner\u001b[0;34m(spike_data, node_list, stimulation_protocol, alpha)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# use a linear regression model to assess if there is a significantly non-zero association between source and target neuron\u001b[39;00m\n\u001b[1;32m     46\u001b[0m linear_model \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mOLS(target_spikes\u001b[38;5;241m.\u001b[39mT, sm\u001b[38;5;241m.\u001b[39madd_constant(X\u001b[38;5;241m.\u001b[39mT))\n\u001b[0;32m---> 47\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m source_nodes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(node_list, idx) \u001b[38;5;66;03m# remove target neuron\u001b[39;00m\n\u001b[1;32m     50\u001b[0m p_values \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mpvalues[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;28mlen\u001b[39m(node_list)] \u001b[38;5;66;03m# p-values of t-test of effect from source to targat neuron (first time step coefficient)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spikeenv/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:335\u001b[0m, in \u001b[0;36mRegressionModel.fit\u001b[0;34m(self, method, cov_type, cov_kwds, use_t, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpinv\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinv_wexog\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    332\u001b[0m             \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalized_cov_params\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    333\u001b[0m             \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m--> 335\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog, singular_values \u001b[38;5;241m=\u001b[39m \u001b[43mpinv_extended\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwexog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalized_cov_params \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\n\u001b[1;32m    337\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog, np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog))\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;66;03m# Cache these singular values for use later.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spikeenv/lib/python3.11/site-packages/statsmodels/tools/tools.py:264\u001b[0m, in \u001b[0;36mpinv_extended\u001b[0;34m(x, rcond)\u001b[0m\n\u001b[1;32m    262\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\n\u001b[1;32m    263\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mconjugate()\n\u001b[0;32m--> 264\u001b[0m u, s, vt \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m s_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(s)\n\u001b[1;32m    266\u001b[0m m \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/spikeenv/lib/python3.11/site-packages/numpy/linalg/linalg.py:1681\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1678\u001b[0m         gufunc \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39msvd_n_s\n\u001b[1;32m   1680\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1681\u001b[0m u, s, vh \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1682\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1683\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for n_obs in np.arange(10, 279, 10):\n",
    "    print('n_obs = ', n_obs)\n",
    "    index_obs = np.sort(np.random.choice(n_neurons, size = n_obs, replace = False))\n",
    "    stimulation_protocol = [[i] for i in index_obs]\n",
    "    spike_data_obs = dict()\n",
    "    spike_data_obs['null'] = spike_data['null'][index_obs]\n",
    "    for intervention in index_obs:\n",
    "        spike_data_obs[str(intervention)] = spike_data[str(intervention)][index_obs]\n",
    "    \n",
    "    # count num. confounders\n",
    "    G_obs = nx.subgraph(G, index_obs)\n",
    "    index_hidden = [node for node in range(n_neurons) if node not in index_obs]\n",
    "    confounders = []\n",
    "    for node in index_hidden:\n",
    "        count = 0\n",
    "        for _, v in G.out_edges(node):\n",
    "            if v in index_obs:\n",
    "                count += 1\n",
    "        if count >= 2:\n",
    "            confounders.append(node)\n",
    "    print('num. confounding variables = ',len(confounders))\n",
    "    \n",
    "    G_learned = SCM_learner(spike_data_obs, \n",
    "                        node_list=index_obs, \n",
    "                        stimulation_protocol=stimulation_protocol, \n",
    "                        alpha = 0.01)\n",
    "    \n",
    "    G_true = nx.subgraph(G, index_obs)\n",
    "\n",
    "    A_true = nx.adjacency_matrix(G_true).todense() \n",
    "    A_learned = nx.adjacency_matrix(G_learned).todense() \n",
    "    A_diff = A_true - A_learned\n",
    "\n",
    "    SHD = np.sum(np.abs(A_true- A_learned))\n",
    "    TP = np.sum( (A_true == 1)*(A_learned==1) )\n",
    "    TN = np.sum( (A_true == 0)*(A_learned==0)) \n",
    "    FP = np.sum(A_diff == -1)\n",
    "    FN = np.sum(A_diff == 1) \n",
    "\n",
    "    print('percentage of nodes observed = ', np.round(G_obs.number_of_nodes() / G.number_of_nodes() * 100, 2), '%')\n",
    "    print('SHD = ', SHD)\n",
    "    print('True positives = ', TP, ', Sensitivity = ', np.round(TP / (TP + FP) * 100, 2) )\n",
    "    print('True negatives = ', TN, ', Specificity = ', np.round(TN / (TN + FN)*100, 2) )\n",
    "    print('False positives = ', FP )\n",
    "    print('False negatives = ', FN )\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17f2fc5-9d89-4f07-8eb2-62d559428586",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- Seems to be a 'critical threshold' for causal discovery, where the learned graph is reliable and accurate whenever we observe more than 28 % of the network \n",
    " - Why this happens is unclear. But somehow the signal of the observed neurons is not strong enough with small samples. \n",
    "     Could it be:\n",
    "     - Some set of 'critical nodes' are almost always included in the sampled data, fx high degree nodes\n",
    "     - The number of confounders relative to observed nodes is reduced\n",
    "- Need to investigate: \n",
    "    - The exact number of nodes required for threshold to be reached\n",
    "    - Maybe look at the out- and in-degree distribution of nodes observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd51cb03-5428-4332-a06e-45144ebaa774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267\n"
     ]
    }
   ],
   "source": [
    "sample_space = list(np.arange(279))\n",
    "sample_space.remove(0)\n",
    "sample_space.remove(6)\n",
    "sample_space.remove(12)\n",
    "sample_space.remove(98)\n",
    "sample_space.remove(111)\n",
    "sample_space.remove(129)\n",
    "sample_space.remove(134)\n",
    "sample_space.remove(142)\n",
    "sample_space.remove(230)\n",
    "sample_space.remove(238)\n",
    "sample_space.remove(143)\n",
    "sample_space.remove(146)\n",
    "sample_space.remove(188)\n",
    "sample_space.remove(270)\n",
    "\n",
    "print(len(sample_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51f29a37-baab-493e-a7f5-76e0224257a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_obs =  71\n",
      "num. confounding variables =  103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 71/71 [00:00<00:00, 80.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  25.45 %\n",
      "SHD =  270\n",
      "True positives =  5 , Sensitivity =  3.57\n",
      "True negatives =  4766 , Specificity =  97.25\n",
      "False positives =  135\n",
      "False negatives =  135\n",
      "\n",
      "n_obs =  73\n",
      "num. confounding variables =  84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 73/73 [00:00<00:00, 87.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  26.16 %\n",
      "SHD =  284\n",
      "True positives =  0 , Sensitivity =  0.0\n",
      "True negatives =  5045 , Specificity =  97.26\n",
      "False positives =  142\n",
      "False negatives =  142\n",
      "\n",
      "n_obs =  75\n",
      "num. confounding variables =  95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 75/75 [00:00<00:00, 82.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  26.88 %\n",
      "SHD =  296\n",
      "True positives =  5 , Sensitivity =  3.27\n",
      "True negatives =  5324 , Specificity =  97.3\n",
      "False positives =  148\n",
      "False negatives =  148\n",
      "\n",
      "n_obs =  77\n",
      "num. confounding variables =  99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 77/77 [00:00<00:00, 79.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  27.6 %\n",
      "SHD =  0\n",
      "True positives =  152 , Sensitivity =  100.0\n",
      "True negatives =  5777 , Specificity =  100.0\n",
      "False positives =  0\n",
      "False negatives =  0\n",
      "\n",
      "n_obs =  79\n",
      "num. confounding variables =  97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 79/79 [00:00<00:00, 79.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of nodes observed =  28.32 %\n",
      "SHD =  0\n",
      "True positives =  177 , Sensitivity =  100.0\n",
      "True negatives =  6064 , Specificity =  100.0\n",
      "False positives =  0\n",
      "False negatives =  0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for n_obs in np.arange(70, 80, 2):\n",
    "    index_obs = list(np.random.choice(128, size = n_obs, replace = False))\n",
    "    index_obs += [129]\n",
    "    index_obs=np.sort(index_obs)\n",
    "    print('n_obs = ', len(index_obs))\n",
    "    \n",
    "    stimulation_protocol = [[i] for i in index_obs]\n",
    "    spike_data_obs = dict()\n",
    "    spike_data_obs['null'] = spike_data['null'][index_obs]\n",
    "    for intervention in index_obs:\n",
    "        spike_data_obs[str(intervention)] = spike_data[str(intervention)][index_obs]\n",
    "    \n",
    "    # count num. confounders\n",
    "    G_obs = nx.subgraph(G, index_obs)\n",
    "    index_hidden = [node for node in range(n_neurons) if node not in index_obs]\n",
    "    confounders = []\n",
    "    for node in index_hidden:\n",
    "        count = 0\n",
    "        for _, v in G.out_edges(node):\n",
    "            if v in index_obs:\n",
    "                count += 1\n",
    "        if count >= 2:\n",
    "            confounders.append(node)\n",
    "    print('num. confounding variables = ',len(confounders))\n",
    "    \n",
    "    G_learned = SCM_learner(spike_data_obs, \n",
    "                        node_list=index_obs, \n",
    "                        stimulation_protocol=stimulation_protocol, \n",
    "                        alpha = 0.01)\n",
    "    \n",
    "    G_true = nx.subgraph(G, index_obs)\n",
    "\n",
    "    A_true = nx.adjacency_matrix(G_true).todense() \n",
    "    A_learned = nx.adjacency_matrix(G_learned).todense() \n",
    "    A_diff = A_true - A_learned\n",
    "\n",
    "    SHD = np.sum(np.abs(A_true- A_learned))\n",
    "    TP = np.sum( (A_true == 1)*(A_learned==1) )\n",
    "    TN = np.sum( (A_true == 0)*(A_learned==0)) \n",
    "    FP = np.sum(A_diff == -1)\n",
    "    FN = np.sum(A_diff == 1) \n",
    "\n",
    "    print('percentage of nodes observed = ', np.round(G_obs.number_of_nodes() / G.number_of_nodes() * 100, 2), '%')\n",
    "    print('SHD = ', SHD)\n",
    "    print('True positives = ', TP, ', Sensitivity = ', np.round(TP / (TP + FP) * 100, 2) )\n",
    "    print('True negatives = ', TN, ', Specificity = ', np.round(TN / (TN + FN)*100, 2) )\n",
    "    print('False positives = ', FP )\n",
    "    print('False negatives = ', FN )\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab58242-f90e-4297-828b-bc4bee0b08bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Notes\n",
    "- when high degree nodes are included in dataset, the learner struggles below 28% threshold. if not included, it still works. might be other 'critical nodes' to consider, like 0 and 6. Node 129 seems to be a problem.\n",
    "- removing all nodes with in_degree > 20 from observed data is also bad...\n",
    "- This info can be useful wrt designing experiments! see how many experiments are needed to get good results when targeting high degree nodes first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d7284b-67dc-44aa-82fb-1614090ee648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikeenv",
   "language": "python",
   "name": "spikeenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
